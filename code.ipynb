{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6690886",
   "metadata": {},
   "source": [
    "\n",
    "# **Principal Strains Prediction Using Inertial Measurement Units**\n",
    "\n",
    "**By Dr. Zainab Altai**  \n",
    "University of Essex  \n",
    "z.altai@essex.ac.uk  \n",
    "December 2024  \n",
    "\n",
    "This Python script is designed for use on Google Colab. It predicts principal strains (e1 and e3) from inertial measurement unit (IMU) data using a pre-trained machine learning model (XCM). The script performs the following tasks:\n",
    "\n",
    "1. Install necessary libraries.  \n",
    "2. Import and preprocess data from MATLAB files.  \n",
    "3. Split data into training and testing sets.  \n",
    "4. Load the pre-trained XCM model.  \n",
    "5. Predict and evaluate principal strains.  \n",
    "\n",
    "---\n",
    "\n",
    "### Instructions to Use the Code\n",
    "1. Clone the repository or copy this script to your Google Colab notebook.\n",
    "2. Update file paths to match your Google Drive directories.\n",
    "3. Run each cell in order.\n",
    "4. Modify the `output_var` to switch between predicting `e1` and `e3`.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab68c2d1",
   "metadata": {},
   "source": [
    "#### 1. Install Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca56d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Install required libraries\n",
    "!pip install mat4py\n",
    "!pip install -Uqq tsai\n",
    "\n",
    "# Import libraries\n",
    "from tsai.all import *\n",
    "import numpy as np\n",
    "from mat4py import loadmat\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04510de1",
   "metadata": {},
   "source": [
    "#### 2. Import and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load MATLAB file (update directory as needed)\n",
    "data = loadmat('/content/drive/MyDrive/ColabNotebooks/AMS_ML/InputData/IMU_FE/DataCombined_IMU_FE_allTasks_ML_data_double_RTH_LTH_PEL.mat')\n",
    "output = data[\"outputs\"]\n",
    "input = data[\"inputs\"]\n",
    "\n",
    "# Load labels (update directory as needed)\n",
    "df = pd.read_csv(r'/content/drive/MyDrive/ColabNotebooks/AMS_ML/InputData/IMU_FE/DataCombined_IMU_FE_allTasks_ML_labels.csv')\n",
    "\n",
    "# Function to extract and restructure data\n",
    "def extractor(data):\n",
    "    all_outputs = np.dstack(list(data[\"outputs\"].values()))\n",
    "    x_axis_input = np.dstack(list(data[\"inputs\"]['x'].values()))\n",
    "    y_axis_input = np.dstack(list(data[\"inputs\"]['y'].values()))\n",
    "    z_axis_input = np.dstack(list(data[\"inputs\"]['z'].values()))\n",
    "    all_inputs = np.concatenate((x_axis_input, y_axis_input, z_axis_input), axis=-1)\n",
    "    return all_outputs, all_inputs\n",
    "\n",
    "# Extract inputs and outputs\n",
    "all_outputs, all_inputs = extractor(data)\n",
    "X2 = np.moveaxis(np.array(all_inputs), -1, 1)\n",
    "\n",
    "# Define output variable (modify for e1 or e3)\n",
    "output_var = 'e1'  # or 'e3'\n",
    "Y2 = np.array(all_outputs[:, :, 0 if output_var == 'e1' else 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2c7609",
   "metadata": {},
   "source": [
    "#### 3. Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cc3dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Ensure labels match data\n",
    "tasks = df['Task'].values\n",
    "assert len(df) == len(X2), \"Label length mismatch.\"\n",
    "\n",
    "# Stratified split\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "for train_index, test_index in sss.split(np.zeros(len(tasks)), tasks):\n",
    "    X_train, X_test = X2[train_index], X2[test_index]\n",
    "    y_train, y_test = Y2[train_index], Y2[test_index]\n",
    "\n",
    "# Save indices and data (update output_dir)\n",
    "output_dir = \"/content/drive/MyDrive/ColabNotebooks/AMS_ML/OutputData/TypicalSplits/XCM/IMU_FE/allTasks_threeIMU/\"\n",
    "train_indices_df = pd.DataFrame(train_index, columns=['Index'])\n",
    "test_indices_df = pd.DataFrame(test_index, columns=['Index'])\n",
    "train_indices_df.to_csv(f'{output_dir}train_indices_{output_var}.csv', index=False)\n",
    "test_indices_df.to_csv(f'{output_dir}test_indices_{output_var}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b92c1",
   "metadata": {},
   "source": [
    "#### 4. Load Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95942596",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load trained model (update path as needed)\n",
    "model_path = f\"/content/drive/MyDrive/ML/Outputs/SubjectSplits/XCM/model_{output_var}_XCM.pk1\"\n",
    "learn = load_learner(model_path, cpu=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48a4766",
   "metadata": {},
   "source": [
    "#### 5. Predict and Evaluate Principal Strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1e1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get predictions\n",
    "probas, _, preds = learn.get_X_preds(X_test)  # X_test = X[splits[1]]\n",
    "predictions = np.array(preds)\n",
    "target = np.array(y_test)\n",
    "\n",
    "# Save predictions and targets\n",
    "np.savetxt(f\"{output_dir}predictions_{output_var}_XCM.csv\", predictions.T, delimiter=',')\n",
    "np.savetxt(f\"{output_dir}originals_{output_var}_XCM.csv\", target.T, delimiter=',')\n",
    "\n",
    "# Evaluation metrics\n",
    "def RMSE(target, predictions):\n",
    "    return np.sqrt(np.mean((target - predictions) ** 2, axis=1))\n",
    "\n",
    "def relRMSE(target, predictions):\n",
    "    nom = RMSE(target, predictions)\n",
    "    denom = 0.5 * (np.ptp(target, axis=1) + np.ptp(predictions, axis=1))\n",
    "    return (nom / denom) * 100\n",
    "\n",
    "def cor_fun(target, predictions):\n",
    "    return np.array([np.corrcoef(target[i], predictions[i])[0, 1] for i in range(target.shape[0])])\n",
    "\n",
    "results = {\n",
    "    \"RMSE\": RMSE(target, predictions),\n",
    "    \"relRMSE\": relRMSE(target, predictions),\n",
    "    \"cor\": cor_fun(target, predictions),\n",
    "}\n",
    "\n",
    "# Save metrics\n",
    "np.savetxt(f\"{output_dir}RMSE_{output_var}_XCM.txt\", results['RMSE'], fmt='%f')\n",
    "np.savetxt(f\"{output_dir}relRMSE_{output_var}_XCM.txt\", results['relRMSE'], fmt='%f')\n",
    "np.savetxt(f\"{output_dir}cor_{output_var}_XCM.txt\", results['cor'], fmt='%f')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}